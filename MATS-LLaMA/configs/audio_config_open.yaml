model:
  name: "audiofree"
  llama_path: "/data/wangwen/HUG/lmsys-vicuna-7b-v1.5"
  clap_path: "/data/wangwen/HUG/msclap/CLAP_weights_2023.pth"

  ckpt: "" # if not "", load model from ckpt for training or evaluation

  freeze_clap: True

  # mapper
  clap_dim: 1024
  mapper_dim: 1024
  prefix_length: 40
  clip_length: 40
  num_layers: 8
  mapping_type: "transformer"

  # mapper for laion ai
  laion_dim: 512
  laion_mapper_dim: 1024

  # noise
  noise_variance: 0.015
  laion_noise_variance: 0.015
  # noise_variance: 1.0
  uniform_noise: False

  # LoRA
  lora: True
  lora_rank: 8
  lora_alpha: 32
  lora_dropout: 0.1

  multi_prompt: True
  prompt_template: "USER: {}\nASSISTANT:"
  prompt_path: "prompts/train_prompt.json"
  test_prompt_path: "prompts/test_prompt.json"
  max_txt_len: 150
  end_sym: "</s>"

datasets:
  audiofree: False
  root: "/data/wangwen/dataset/audio"

  train_data:
    CREMA_D_Emo: # 73k
      path: "../data/CREMA-D/CREMA-D_only_audio_test_d_train.json"
      sample_ratio: 50
      special_token: "[emotion event]"
    RAVDESS_Emo: # 1.5k
      path: "../data/RAVDESS/RAVDESS_only_audio_test_train.json"
      sample_ratio: 50
      special_token: "[emotion event]"
    VOCAL: # 17k
      path: "../data/VocalSound/vocalsound_tr_audio.json"
      sample_ratio: 20
      special_token: "[vocal event]"
    salmonn_caption: # 434k
      path: "../data/Salmonn/salmonn_audio_caption.json" #434K
      sample_ratio: 200
      special_token: "[audio caption]"
    audiocaps_caption: # 47k
      path: "../data/Salmonn/audiocaps.json" #47K
      sample_ratio: 40
      special_token: "[audio caption audiocaps]"
    clotho_caption: #19k
      path: "../data/Salmonn/clotho.json" #19K
      sample_ratio: 40
      special_token: "[audio caption clotho]"
    MACS: # 17.27k
      path: "../data/macs/macs_train_cap.json" # 17.27k
      sample_ratio: 50
      special_token: "[audio caption]"
    AudioSet: # 90k
      path: "../data/AudioSets/as_strong_train_audio_final_final.json" #101K
      sample_ratio: 50
      special_token: "[multi events]"
    FSD50K: # 40
      path: "../data/FSD50k/fsd50k_tr_val_audio.json" #77K; 200-class
      sample_ratio: 50
      special_token: "[multi events]"
    VGGSound:
      path: "../data/VGGSound/vggsound_tr_audio.json" #97K; 310-class
      sample_ratio: 50
      special_token: "[single event]"
    DCASE: # 53k
      path: "../data/DCASE_2017/dcase17_train_audio.json" #16K; 17-class
      sample_ratio: 20
      special_token: "[single event]"
    ESC: # 2k
      path: "../data/ESC-50/esc50_train.json" #22K; 50-class
      sample_ratio: 20
      special_token: "[single event]"
    UrbanSound: # 9k
      path: "../data/UrbanSound8K/urbansound8K.json" # 19K; 10-class
      sample_ratio: 20
      special_token: "[single event]"
    TUT: # 4.6k
      path: "../data/TUT/tut_train_audio.json" #14K; 15-class
      sample_ratio: 20
      special_token: "[scene event]"
    SESA: # 480
      path: "../data/SESA/SESA_tr_audio.json" # 7K; 4-class
      sample_ratio: 20
      special_token: "[surveillance event]"
    BJO: # 236
      path: "../data/beijing_opera/beijing_opera_test_train.json" #12K; 4-class
      sample_ratio: 20
      special_token: "[instruction event]"
    Genres: #1k
      path: "../data/music_genres/genres_test_train.json" # 20K; 10-class
      sample_ratio: 20
      special_token: "[music genres]"
    GAMA_Cla_music: # 630k
      path: "../data/openAQAData/cla_label_music_close_final.json"
      sample_ratio: 180
      special_token: "[music classification]"
    MusicCaps: # 2.6k
      path: "../data/MusicCaps/MusicCaps_train.json" #2.6K
      sample_ratio: 50
      special_token: "[music caption]"
    GAMA_Cap_music: # 25.7k
      path: "../data/openAQAData/captioning_music_close.json" # 26k
      sample_ratio: 50
      special_token: "[music caption]"
    ClothoAQA: # 6.1k
      path: "../data/clotho_aqa_v2/clotho_aqa_train_clean.json" #20K
      sample_ratio: 50
      special_token: "[audio qa]"
    open_ended: # 2467k
      path: "../data/openAQAData/combine_aqa_except_no_a_final_final_final.json" # 2547k
      sample_ratio: 300
      special_token: "[open ended]"
    music_aqa: # 118k
      path: "../data/MusicQA/conbine_musicaq.json" # 1207k
      sample_ratio: 300
      special_token: "[open ended]"

  valid_ann_path: "../data/AudioCaps/AudioCaps_audio_stage1_test.json"
  test_ann_path: "../data/AudioCaps/AudioCaps_audio_stage1_test.json"
  special_token: "[audio caption audiocaps]"
  save_file: "audiocaps_pred"

  resampling_rate: 44100
  audio_duration: 7
  resample: True

run:
  start_epoch: 0
  # log & settings
  seed: 42
  output_dir: "results/audio-supervision/test" # stage2_model_laion_librispeech
  laion_output_dir: "results_laion/speech_noise_0.031_mapper_1024"
  evaluate: False

  log_freq: 50
  epoch_based: False
  iters_per_epoch: 3000
  accum_grad_iters: 4
  batch_size_train: 12
  batch_size_eval: 8
  num_workers: 8

  save_epoch: 29

  device: "cuda"
  use_distributed: True
  amp: False
  world_size: 4
  dist_url: "env://"

  # optimizer & scheduler
  optims:
    max_epoch: 30
    warmup_steps: 3000
    warmup_start_lr: 1e-7
    init_lr: 3e-5
    min_lr: 0
    weight_decay: 0.05
    beta2: 0.999

generate:
  max_new_tokens: 200
  num_beams: 4
  do_sample: False
  min_length: 1
  temperature: 1.0
  top_k: 50
  top_p: 0.9
  no_repeat_ngram_size: 2
  repetition_penalty: 2.0
  length_penalty: 1.0
